{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extração completa, verifique arquivo json\n"
     ]
    }
   ],
   "source": [
    "from distutils import extension\n",
    "import json\n",
    "import re\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL_BASE = \"https://www.indeed.com\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    cidade = input(\"Nome da cidade:\")\n",
    "\n",
    "    keywords = input(\"Palavras-chaves da vaga:\")\n",
    "\n",
    "    npaginas = input(\"Selecione o número de páginas para análise:\")\n",
    "\n",
    "    cidade = '+'.join(cidade.split(' '))\n",
    "    keywords = '+'.join(keywords.split(' '))\n",
    "    url_scrape = URL_BASE + \"/jobs?q=\" + keywords + \"&l=\" + cidade\n",
    "    npaginas = int(npaginas)\n",
    "    dados = data(url_scrape, npaginas)\n",
    "    with open('data.json', 'w') as fp:\n",
    "        json.dump(dados, fp, sort_keys=True, indent=4, ensure_ascii=False)\n",
    "\n",
    "\n",
    "def data(url_scrape, npaginas):\n",
    "    data = []\n",
    "    for i in range(0, npaginas):\n",
    "        extension = \"\"\n",
    "        if i != 0:\n",
    "            extension = \"&start\" + str(i*10)\n",
    "        url = url_scrape + extension\n",
    "        req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        web_page = urlopen(req).read()\n",
    "        soup = BeautifulSoup(web_page, 'html.parser')\n",
    "        data = get_data_from_webpage(data, soup)\n",
    "    return data\n",
    "\n",
    "\n",
    "def extracao(job, div):\n",
    "    for a in div.findAll('a', attrs={'class': 'jobtitle turnstileLink'}):\n",
    "        job['Vaga'] = a['Vaga']\n",
    "    for a1 in div.findAll('a', attrs={'data-tn-element': 'companyName'}):\n",
    "        job['Empresa'] = a1.text.strip()\n",
    "    for span in div.findAll('span', attrs={'class': 'ratingsContent'}):\n",
    "        job['Avaliação'] = span.text.strip()\n",
    "    for span1 in div.findAll('span', attrs={'class': 'location acessible-contrast-color-location'}):\n",
    "        job['Localização'] = span1.text.strip()\n",
    "    for div1 in div.findAll('div', attrs={'class': 'summary'}):\n",
    "        resumo = div1.text.strip()\n",
    "        job['Resumo'] = re.sub(' +', ' ', resumo.replace(\"\\n\", \"\"))\n",
    "    for span2 in div.findAll('span', attrs={'class': 'date'}):\n",
    "        job['Data'] = span2.text.strip()\n",
    "    return job\n",
    "\n",
    "\n",
    "def get_data_from_webpage(data, soup):\n",
    "    job_posts = []\n",
    "    for div in soup.findAll('div', attrs={'class': 'jobsearch-SerpJobCard unifiedRow row result'}):\n",
    "        job = dict()\n",
    "        job = extracao(job, div)\n",
    "        job_posts.append(div['data-jk'])\n",
    "        single_job_post_extension_url = \"https://www.indeed.com/viewjob?jk=\" + \\\n",
    "            div['data-jk']\n",
    "        job['url'] = single_job_post_extension_url\n",
    "        req = Request(single_job_post_extension_url,\n",
    "                      headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        web_page = urlopen(req).read()\n",
    "        job_soup = BeautifulSoup(web_page, 'html.parser')\n",
    "\n",
    "        for inside_div in job_soup.findAll('div', attrs={'class': 'jobsearch-jobDescriptionText'}):\n",
    "            details = inside_div.text.strip()[:100] + \"...\"\n",
    "            job['Detalhes'] = re.sub(' +', ' ', details.replace(\"\\n\", \"\"))\n",
    "        data.append(job)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    print('Extração completa, verifique arquivo json')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4e35ed6d4fbc4c2049b2a23d3bbee0c89445d3c7a02bf5b5ceabf610d650a451"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
